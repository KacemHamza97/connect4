{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_RL_connect4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRCg_zp9_Wjn"
      },
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2\n",
        "! pip install \n",
        "!pip install stable-baselines3[extra]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SVMLf4S_bcm"
      },
      "source": [
        "import gym \n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E4xAu2baZMF"
      },
      "source": [
        "NUM_ROWS = 6\n",
        "NUM_COLS = 7\n",
        "NUM2WIN = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEFgNAk9_1Z7"
      },
      "source": [
        "class CustumEnv(Env):\n",
        "    NUM_ROWS = 6\n",
        "    NUM_COLS = 7\n",
        "    NUM2WIN = 4\n",
        "    def __init__(self):\n",
        "        # Actions we can take: throw the rock in one of the 7 column\n",
        "        self.action_space = Discrete(NUM_COLS)\n",
        "        # state matrix\n",
        "        self.observation_space = Box(low=np.array([-1 for i in range(7*6)]).reshape(6,7), \n",
        "                                     high=np.array([1 for i in range(7*6)]).reshape(6,7),\n",
        "                                     dtype=np.int8)\n",
        "        # starting borad matrix\n",
        "        self.state = np.zeros((6,7))\n",
        "        \n",
        "    def step(self, action,player=-1): \n",
        "        #action=column number\n",
        "        # Apply action\n",
        "        # throw the rock on the top of the existing/empty selected column\n",
        "        j = 0\n",
        "        #print(\"Before Action\")\n",
        "        #print(self.state)\n",
        "        #print(self.state)\n",
        "        while j + 1 < self.NUM_ROWS and self.state[j + 1][action] == 0:\n",
        "            j += 1\n",
        "        self.state[j][action] = player\n",
        "        #print(\"After Action\")\n",
        "        #print(self.state)\n",
        "    \n",
        "        winner=\"\"\n",
        "        # reward\n",
        "        done = False\n",
        "        reward = 0\n",
        "        for i in range(self.NUM_ROWS - self.NUM2WIN + 1):\n",
        "            for j in range(self.NUM_COLS - self.NUM2WIN + 1):\n",
        "                sub_state = self.state[i:i + self.NUM2WIN, j:j + self.NUM2WIN]\n",
        "                if np.max(np.sum(sub_state, axis=0)) == self.NUM2WIN or np.max(np.sum(sub_state, axis=1)) == self.NUM2WIN or np.trace(sub_state) == self.NUM2WIN or np.trace(np.transpose(sub_state)) == self.NUM2WIN: # human having 4 consecutive pieces in a column or row or both diagonals\n",
        "                    done = True\n",
        "                    reward = -10\n",
        "                    winner=\"Human\"\n",
        "                elif np.min(np.sum(sub_state, axis=0)) == -self.NUM2WIN or np.min(np.sum(sub_state, axis=1)) == -self.NUM2WIN or np.trace(sub_state) == -self.NUM2WIN or np.trace(np.transpose(sub_state)) == -self.NUM2WIN:\n",
        "                    done = True\n",
        "                    reward = 10\n",
        "                    winner=\"Agent\"\n",
        "                \n",
        "        if -np.max(np.sum(self.state, axis=0))==np.sum(self.state[:][action%4]) and not done:\n",
        "                  reward=1   \n",
        "        elif not done:\n",
        "                  reward=-1\n",
        "\n",
        "                \n",
        "        \n",
        "        info = {}\n",
        "        info[\"winner\"]=winner\n",
        "        \n",
        "        # Return step information\n",
        "        return self.state, reward, done,info\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset\n",
        "        self.state = np.zeros((6,7))\n",
        "        return self.state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_lEz6PA_b-1"
      },
      "source": [
        "env = CustumEnv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHBvtkF__cCS",
        "outputId": "62a4d32f-0701-4234-9c37-f38d56bf5c52"
      },
      "source": [
        "env.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJO59XOf_cFu"
      },
      "source": [
        "from stable_baselines3.common.env_checker import check_env"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrDLFJKX_cJQ",
        "outputId": "973d88ff-c1e5-402b-e0fc-e20fbf1f9928"
      },
      "source": [
        "check_env(env,warn=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/env_checker.py:131: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  f\"Your observation {key} has an unconventional shape (neither an image, nor a 1D vector). \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keGptODW_cMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3220b1-566e-4749-e56d-3a61a1b047f8"
      },
      "source": [
        "episodes = 20\n",
        "n_wins=0\n",
        "for episode in range(1, episodes+1):\n",
        "    current_state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    human_play=True\n",
        "    while not done:\n",
        "        if human_play:\n",
        "          env.step(np.random.choice(np.arange(0,7)))\n",
        "          print(\"Random is playing: \")\n",
        "          human_play=False\n",
        "          print(\"Current State:\")\n",
        "          print(current_state) \n",
        "          continue\n",
        "        else: \n",
        "          print(\"Agent is playing: \")\n",
        "          action = env.action_space.sample()\n",
        "          \n",
        "          current_state, reward, done, info = env.step(action)\n",
        "          print(\"Current action is: \",action)\n",
        "          print(\"Collected reward is: \",reward)\n",
        "          score+=reward\n",
        "          print(\"Current State:\")\n",
        "          print(current_state)  \n",
        "          human_play=True\n",
        "    if done:\n",
        "      print(\"Game was done at episode {} with a score of {}\".format(episode,score))   \n",
        "      if info[\"winner\"]==\"Agent\":\n",
        "        n_wins+=1   \n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [ 0.  0. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [ 0.  0. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [-1.  0. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [-1.  0. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [-1.  0. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [-1.  0. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1.  0.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  1.  1. -1.  0.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1.  0.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1.  0.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [ 0.  0. -1.  0. -1.  1. -1.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  1.]\n",
            " [ 0.  0. -1.  0. -1.  1. -1.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  1.]\n",
            " [ 0.  0. -1.  0. -1.  1. -1.]\n",
            " [ 0.  0.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  1.]\n",
            " [ 0.  0. -1.  0. -1.  1. -1.]\n",
            " [ 0.  1.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  1.]\n",
            " [ 0.  0. -1.  0. -1.  1. -1.]\n",
            " [-1.  1.  1.  1.  1. -1. -1.]\n",
            " [-1. -1. -1.  1. -1.  1.  1.]]\n",
            "Game was done at episode 1 with a score of -12\n",
            "Episode:1 Score:-12\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0. -1.  0.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0. -1. -1.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0. -1. -1.  1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1. -1.  1.]]\n",
            "Game was done at episode 2 with a score of -5\n",
            "Episode:2 Score:-5\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  0.  1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0.  1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  1.  1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [ 1.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [ 1.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]\n",
            " [ 1.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  1.  0.  0.]\n",
            " [ 1.  0. -1.  1.  1.  0.  0.]\n",
            " [-1. -1. -1.  1.  1. -1.  0.]]\n",
            "Game was done at episode 3 with a score of -8\n",
            "Episode:3 Score:-8\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  0.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0. -1. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]\n",
            " [ 0. -1. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  1. -1.  0.  0.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  1. -1.  0.  0.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0.  0.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1. -1.  0.  0.]\n",
            " [ 0. -1.  1.  1. -1.  0.  1.]\n",
            " [ 0. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1. -1.  0.  0.]\n",
            " [ 0. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1. -1.  1. -1.  0.  0.]\n",
            " [ 0. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1. -1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1. -1.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1. -1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1. -1.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1. -1. -1.  1.  1.  1.]]\n",
            "Game was done at episode 4 with a score of -10\n",
            "Episode:4 Score:-10\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0. -1.  0.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0. -1.  0.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0. -1.  0. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  1.  0.  0.  0.]\n",
            " [ 0.  1.  0. -1.  0. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  1.  0.  0.  0.]\n",
            " [ 0.  1. -1. -1.  0. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  1.  0.  0.  0.]\n",
            " [ 0.  1. -1. -1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  1.  0.  0.  0.]\n",
            " [ 0.  1. -1. -1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  1.  1.  0.  0.  0.]\n",
            " [ 0.  1. -1. -1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  1.  1.  0.  0.  0.]\n",
            " [-1.  1. -1. -1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  1.  1.  0.  0.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  1.  1.  0.  0.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  1.  1.  0.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [-1.  1.  1.  1.  0.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [-1.  1.  1.  1.  0.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1.  0.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  0.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1.  0.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1. -1.]\n",
            " [ 0.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  1.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  1.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  1.  0.  0.  1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  1.  0.  0.  1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  1.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0. -1.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0. -1.  0.  0. -1.  1.]\n",
            " [-1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1. -1.  0.  1.  1.]\n",
            " [ 1. -1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1.  1.  1.]\n",
            " [-1.  1. -1. -1.  1. -1.  1.]]\n",
            "Game was done at episode 5 with a score of -20\n",
            "Episode:5 Score:-20\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1. -1.  0.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1. -1.  0.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1. -1.  0.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1. -1.  1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1. -1.  1. -1.  1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1. -1.  1. -1.  1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1. -1.  1. -1.  1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1. -1.  1. -1.  1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0. -1. -1.  0.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0. -1. -1.  0.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0. -1. -1.  0.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1. -1.  0.  0.]\n",
            " [-1.  0. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  1. -1. -1.  0.  0.]\n",
            " [-1.  0. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 0.  0.  1. -1. -1.  0.  0.]\n",
            " [-1. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1. -1.  1.  1. -1.]]\n",
            "Game was done at episode 6 with a score of -7\n",
            "Episode:6 Score:-7\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1. -1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1. -1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [-1.  0.  1. -1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1.  0.  0.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1.  0.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1. -1.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1. -1.  1. -1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1. -1.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1. -1.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1.  0.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1. -1.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1. -1.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1. -1.  0. -1.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1. -1.  0. -1.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1. -1.  0. -1.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0.  0.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1. -1.  0. -1.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0. -1.]\n",
            " [-1.  1.  0. -1. -1.  0. -1.]\n",
            " [-1. -1. -1.  1. -1.  0. -1.]\n",
            " [ 1. -1.  1.  1. -1. -1. -1.]\n",
            " [-1. -1.  1. -1.  1.  1.  1.]]\n",
            "Game was done at episode 7 with a score of -17\n",
            "Episode:7 Score:-17\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  0.  0.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 1.  0. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 1.  0. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  0.  0.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  0. -1.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]\n",
            " [ 1.  0. -1.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0. -1.]\n",
            " [ 1.  0. -1.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0. -1.  0. -1.]\n",
            " [ 1.  0. -1.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0. -1.]\n",
            " [ 1.  0.  1.  0. -1.  0. -1.]\n",
            " [ 1.  0. -1.  0.  1. -1. -1.]\n",
            " [ 1.  1. -1.  0.  1.  1. -1.]\n",
            " [-1.  1.  1.  0. -1. -1.  1.]]\n",
            "Game was done at episode 8 with a score of -9\n",
            "Episode:8 Score:-9\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  0.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1. -1.  0.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [ 0.  1.  1.  0.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  0.]\n",
            " [-1.  1.  1.  0.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 1. -1. -1.  0. -1.  0.  0.]\n",
            " [-1.  1.  1.  0.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  0.]\n",
            " [-1.  1.  1.  0.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  0.]\n",
            " [-1.  1.  1.  1.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  0.  0.]\n",
            " [ 0.  1. -1.  0.  1.  0.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  0.]\n",
            " [-1.  1.  1.  1.  1. -1.  1.]\n",
            " [ 1. -1.  1. -1. -1. -1.  1.]]\n",
            "Game was done at episode 9 with a score of -10\n",
            "Episode:9 Score:-10\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  1. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0. -1.]\n",
            " [ 0.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1. -1.]\n",
            " [ 0.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  1.  0.  0.  0.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  0.  0.  0.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  0.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  0.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  1.  0.  0.  0.  1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [ 0.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [-1.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0.  0. -1.  1.]\n",
            " [-1.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0. -1. -1.  1.]\n",
            " [-1.  1.  1.  0.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0.  1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.]\n",
            " [ 0. -1. -1.  0. -1. -1.  1.]\n",
            " [-1.  1.  1. -1.  1.  1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Game was done at episode 10 with a score of -15\n",
            "Episode:10 Score:-15\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  1. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1. -1.  1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1. -1.  1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0. -1. -1.  1.  0.  0.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0. -1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0. -1.]\n",
            " [ 0.  0.  0.  0.  1.  0.  1.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [ 0. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0. -1.]\n",
            " [ 0.  0.  0.  0.  1.  0.  1.]\n",
            " [ 0.  0.  0.  0.  1.  0. -1.]\n",
            " [ 0.  0.  0.  0. -1.  0. -1.]\n",
            " [-1. -1. -1. -1.  1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  1.  1.]]\n",
            "Game was done at episode 11 with a score of -8\n",
            "Episode:11 Score:-8\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1. -1.  0.  1.  0. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1.  0.]\n",
            " [ 1. -1.  0.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1. -1.]\n",
            " [ 1. -1.  0.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1.  0.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  0. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [-1.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [-1.  0.  0. -1.  0. -1. -1.]\n",
            " [ 1.  0. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [-1.  0.  0. -1.  1. -1. -1.]\n",
            " [ 1.  0. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  1.  0.  1.  0.]\n",
            " [ 0.  0.  0. -1.  0.  1.  0.]\n",
            " [-1.  0.  0. -1.  1. -1. -1.]\n",
            " [ 1. -1. -1. -1. -1.  1. -1.]\n",
            " [ 1. -1.  1.  1.  1. -1.  1.]]\n",
            "Game was done at episode 12 with a score of -9\n",
            "Episode:12 Score:-9\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 0.  0. -1.  0.  0.  1. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  0. -1.  0.  0.  1. -1.]\n",
            " [-1.  0. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 0.  0. -1.  0.  0.  1. -1.]\n",
            " [-1. -1. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 1.  0. -1.  0.  0.  1. -1.]\n",
            " [-1. -1. -1.  0.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 1. -1. -1.  0.  0.  1. -1.]\n",
            " [-1. -1. -1.  0.  1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  1.]\n",
            " [ 1. -1. -1.  0.  0.  1. -1.]\n",
            " [-1. -1. -1.  1.  1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 0. -1.  0.  0.  0. -1.  1.]\n",
            " [ 1. -1. -1.  0.  0.  1. -1.]\n",
            " [-1. -1. -1.  1.  1.  1.  1.]]\n",
            "Game was done at episode 13 with a score of -8\n",
            "Episode:13 Score:-8\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  1.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  1.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1. -1.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1. -1.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1. -1.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  1. -1.  0.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0. -1.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  0.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1.  0.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0.  0.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  0.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  1.  0.]\n",
            " [ 1.  0.  0.  1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  1.  0.]\n",
            " [ 1.  0. -1.  1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  0.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  1.  0.  1.  0.]\n",
            " [ 1.  0. -1.  1.  0. -1.  0.]\n",
            " [ 1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 1.  1.  1.  1. -1. -1.  0.]\n",
            " [-1.  1.  1. -1. -1.  1.  1.]\n",
            " [-1.  1. -1.  1. -1.  1. -1.]]\n",
            "Game was done at episode 14 with a score of -15\n",
            "Episode:14 Score:-15\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  0.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  0.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  0.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  1.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1.  0.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  1.  0.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  0.  0.]\n",
            " [ 0.  0.  1.  0. -1.  1.  0.]\n",
            " [ 0.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0. -1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  1.  0.]\n",
            " [ 0.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0. -1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  1.  0.]\n",
            " [ 0.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0. -1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  1.  0.]\n",
            " [ 0.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0. -1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  1.  0.]\n",
            " [ 0.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0. -1.  0.  0.]\n",
            " [ 0. -1.  1.  0. -1.  1.  0.]\n",
            " [-1.  1. -1.  0.  1.  1.  0.]\n",
            " [-1. -1.  1.  0. -1. -1.  1.]\n",
            " [ 1.  1.  1.  1. -1.  1. -1.]]\n",
            "Game was done at episode 15 with a score of -9\n",
            "Episode:15 Score:-9\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0. -1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0. -1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1.  0. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 1.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1. -1. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  1.  0.  0.]\n",
            " [-1.  0. -1. -1. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  1.  1.  0.  0.]\n",
            " [-1.  0. -1. -1. -1.  0.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  1.  1.  0.  0.]\n",
            " [-1.  0. -1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 1.  0. -1.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  0.  0.]\n",
            " [-1.  0. -1.  0. -1.  0.  0.]\n",
            " [ 1.  0.  1.  1.  1.  0.  0.]\n",
            " [-1.  1. -1. -1. -1. -1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  1.]]\n",
            "Game was done at episode 16 with a score of -11\n",
            "Episode:16 Score:-11\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  1.  1.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  0.  0.  1.  1.  0.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 1.  0.  0.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  1.  0.]\n",
            " [ 1.  0.  0.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  0.  0.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  0.  0.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0. -1.  0.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  0. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1.  0.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  0. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1. -1.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  0. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1. -1.  0.]\n",
            " [ 0.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1.  0.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  0.  0.  1. -1. -1.  0.]\n",
            " [-1. -1.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [-1.  1.  0.  1. -1. -1.  0.]\n",
            " [-1. -1.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  1.  0.  0.]\n",
            " [ 0. -1.  0.  0.  1.  0.  0.]\n",
            " [-1.  1.  0.  1. -1. -1.  0.]\n",
            " [-1. -1.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  1.  0.  0.]\n",
            " [ 0. -1.  0.  0.  1.  0.  0.]\n",
            " [-1.  1.  0.  1. -1. -1.  0.]\n",
            " [-1. -1.  0. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  1.  0.  0.]\n",
            " [ 0. -1.  0.  0.  1.  0.  0.]\n",
            " [-1.  1.  0.  1. -1. -1.  0.]\n",
            " [-1. -1. -1. -1. -1.  1.  0.]\n",
            " [ 1.  1. -1.  1.  1. -1.  1.]]\n",
            "Game was done at episode 17 with a score of -7\n",
            "Episode:17 Score:-7\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0.  0.  0.  0.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1.  0.  0.  0.  1.  0.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  0.  0.  1.  0.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  0.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  0.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  0.  0.  0.]\n",
            " [-1.  1. -1.  0.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1. -1.  0.  0.  0. -1.]\n",
            " [-1.  1. -1.  0.  0.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  1. -1.  0.  0.  0. -1.]\n",
            " [-1.  1. -1.  0.  0.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  1. -1.  0.  0.  0. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1.  1. -1.  0.  0.  0. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  0.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  0.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  0. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0.  0. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0.  0. -1.  1.]\n",
            " [ 1.  1. -1.  0. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  0.  1.  0.]\n",
            " [ 1.  0. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  0. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1.  0. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  0. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1.  0. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  0. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1.  0. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0. -1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1. -1. -1.  0. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  0.  1.  1.  0.]\n",
            " [ 1. -1. -1. -1. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[-1.  0.  0.  0.  0.  1.  0.]\n",
            " [ 1.  0.  1.  0.  0. -1.  0.]\n",
            " [-1.  0.  1.  1.  1.  1.  0.]\n",
            " [ 1. -1. -1. -1. -1. -1.  1.]\n",
            " [ 1.  1. -1.  1. -1. -1. -1.]\n",
            " [-1.  1. -1.  1. -1.  1.  1.]]\n",
            "Game was done at episode 18 with a score of -16\n",
            "Episode:18 Score:-16\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]\n",
            " [ 0. -1.  0.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  0\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [-1. -1.  0.  1.  0.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  0.  0.  0.  0.]\n",
            " [-1. -1.  0.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  0.  0.  0. -1.]\n",
            " [-1. -1.  0.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  0.  0.  0. -1.]\n",
            " [-1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1.  0.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  0.  0.  0. -1.]\n",
            " [-1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  1.  0.  0. -1.]\n",
            " [-1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  4\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1.  0.  1. -1.  0. -1.]\n",
            " [-1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1.  0. -1.]\n",
            " [-1. -1.  1.  1. -1.  0.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1.  0. -1.]\n",
            " [-1. -1.  1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1.  0. -1.]\n",
            " [-1. -1.  1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  5\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1. -1. -1.]\n",
            " [-1. -1.  1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0.  0.  0.  1.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1. -1. -1.]\n",
            " [-1. -1.  1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  1.]\n",
            " [ 0. -1.  0.  1.  0.  0.  1.]\n",
            " [ 1. -1.  0.  1. -1. -1. -1.]\n",
            " [-1. -1.  1.  1. -1. -1.  1.]\n",
            " [ 1. -1.  1.  1. -1. -1.  1.]]\n",
            "Game was done at episode 19 with a score of -12\n",
            "Episode:19 Score:-12\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]]\n",
            "Agent is playing: \n",
            "Current action is:  6\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  1.  0.  0.  0.  0. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0.  0.  0.  0. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  3\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  1.  0. -1.  0.  0. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  1. -1. -1.  0.  0. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  1.  0.  0.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  2\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0.  0.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1.  0. -1.  1.  0.  0.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1. -1.  1.  0.  0.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Random is playing: \n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  1.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Agent is playing: \n",
            "Current action is:  1\n",
            "Collected reward is:  -1\n",
            "Current State:\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  0.  0.  0.  0.  0.]\n",
            " [ 0. -1.  1.  0.  0.  1.  0.]\n",
            " [ 1. -1. -1.  1.  0.  1.  0.]\n",
            " [ 1.  1. -1. -1.  0.  1. -1.]]\n",
            "Game was done at episode 20 with a score of -8\n",
            "Episode:20 Score:-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goTIBoJD_cPe",
        "outputId": "13ebac3c-46c5-4199-f461-5a87a0e73601"
      },
      "source": [
        "model = PPO(\"MlpPolicy\", env, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ_yW_ZM_cS0",
        "outputId": "f2368b97-2588-48cc-8598-2ab7d7d89d75"
      },
      "source": [
        "model.learn(total_timesteps=100000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 8.63     |\n",
            "|    ep_rew_mean     | 17       |\n",
            "| time/              |          |\n",
            "|    fps             | 351      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.71        |\n",
            "|    ep_rew_mean          | 17.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 297         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 13          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011472172 |\n",
            "|    clip_fraction        | 0.0929      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.94       |\n",
            "|    explained_variance   | -0.0165     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.21        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0241     |\n",
            "|    value_loss           | 49.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 9.18        |\n",
            "|    ep_rew_mean          | 18          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016519414 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.92       |\n",
            "|    explained_variance   | -1.09       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.13        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0223     |\n",
            "|    value_loss           | 8.53        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.1        |\n",
            "|    ep_rew_mean          | 18.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 277         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 29          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015946377 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.88       |\n",
            "|    explained_variance   | -0.0356     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.93        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0314     |\n",
            "|    value_loss           | 7.36        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 11.2        |\n",
            "|    ep_rew_mean          | 20.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 273         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013327421 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.84       |\n",
            "|    explained_variance   | 0.0613      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.59        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0242     |\n",
            "|    value_loss           | 8.25        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 12.9        |\n",
            "|    ep_rew_mean          | 21.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 270         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 45          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010774489 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0.119       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.57        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0204     |\n",
            "|    value_loss           | 8.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.4        |\n",
            "|    ep_rew_mean          | 22.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 268         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012494727 |\n",
            "|    clip_fraction        | 0.087       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0.175       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.62        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0203     |\n",
            "|    value_loss           | 9.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.9        |\n",
            "|    ep_rew_mean          | 22.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 267         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011586378 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0.215       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.53        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0209     |\n",
            "|    value_loss           | 9.37        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 14.3        |\n",
            "|    ep_rew_mean          | 23.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 266         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010889212 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.69       |\n",
            "|    explained_variance   | 0.252       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.96        |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0167     |\n",
            "|    value_loss           | 9.59        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 14.7        |\n",
            "|    ep_rew_mean          | 23.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 265         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010548447 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.65       |\n",
            "|    explained_variance   | 0.303       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.2         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0182     |\n",
            "|    value_loss           | 7.19        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.4        |\n",
            "|    ep_rew_mean          | 24.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 264         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 85          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015784457 |\n",
            "|    clip_fraction        | 0.178       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0.772       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.18        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0288     |\n",
            "|    value_loss           | 2.67        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 16.2        |\n",
            "|    ep_rew_mean          | 25.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 264         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 92          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016989121 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.55       |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.21        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.028      |\n",
            "|    value_loss           | 2.24        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 16.8        |\n",
            "|    ep_rew_mean          | 25.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 263         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013199205 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0.886       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.948       |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0257     |\n",
            "|    value_loss           | 1.63        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.5        |\n",
            "|    ep_rew_mean          | 26.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 263         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011719789 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0.884       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.42        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0225     |\n",
            "|    value_loss           | 1.84        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 17.6        |\n",
            "|    ep_rew_mean          | 26.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 262         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012588251 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.452       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0215     |\n",
            "|    value_loss           | 1.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.1        |\n",
            "|    ep_rew_mean          | 27.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 262         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 124         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011418352 |\n",
            "|    clip_fraction        | 0.0983      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.379       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0193     |\n",
            "|    value_loss           | 1.13        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.2        |\n",
            "|    ep_rew_mean          | 27.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 262         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 132         |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010081748 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.958       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.123       |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    value_loss           | 0.747       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 18.3         |\n",
            "|    ep_rew_mean          | 27.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 261          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0089552635 |\n",
            "|    clip_fraction        | 0.107        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.32        |\n",
            "|    explained_variance   | 0.961        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.758        |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.0168      |\n",
            "|    value_loss           | 0.702        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.5        |\n",
            "|    ep_rew_mean          | 27.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 261         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 148         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010455304 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.109       |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    value_loss           | 0.676       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 18.7         |\n",
            "|    ep_rew_mean          | 27.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 261          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 156          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0106076505 |\n",
            "|    clip_fraction        | 0.142        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.973        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.141        |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.0178      |\n",
            "|    value_loss           | 0.503        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 164         |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017023977 |\n",
            "|    clip_fraction        | 0.19        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.99        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.126       |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.021      |\n",
            "|    value_loss           | 0.187       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.6        |\n",
            "|    ep_rew_mean          | 27.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 172         |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012052164 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00627     |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    value_loss           | 0.205       |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 18.8      |\n",
            "|    ep_rew_mean          | 27.8      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 260       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 180       |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0109837 |\n",
            "|    clip_fraction        | 0.128     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.26     |\n",
            "|    explained_variance   | 0.979     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.127     |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -0.0155   |\n",
            "|    value_loss           | 0.405     |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.6        |\n",
            "|    ep_rew_mean          | 27.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 188         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011863592 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.25       |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0285      |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    value_loss           | 0.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 196         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010371579 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 0.979       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.078       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0172     |\n",
            "|    value_loss           | 0.398       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 53248       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012033638 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0076      |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    value_loss           | 0.207       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 212         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015013958 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00274     |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    value_loss           | 0.0989      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 19          |\n",
            "|    ep_rew_mean          | 28          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 220         |\n",
            "|    total_timesteps      | 57344       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010981457 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00773     |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    value_loss           | 0.122       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 228         |\n",
            "|    total_timesteps      | 59392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013873173 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.999       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.018      |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    value_loss           | 0.0217      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011675684 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0934      |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    value_loss           | 0.15        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 244         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015099997 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.988       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00217     |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.0123     |\n",
            "|    value_loss           | 0.239       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 252         |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013584657 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00881     |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    value_loss           | 0.137       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 260         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012216498 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.114       |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0133     |\n",
            "|    value_loss           | 0.218       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.7        |\n",
            "|    ep_rew_mean          | 27.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 268         |\n",
            "|    total_timesteps      | 69632       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011602808 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.19       |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0114      |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    value_loss           | 0.077       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.7        |\n",
            "|    ep_rew_mean          | 27.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 35          |\n",
            "|    time_elapsed         | 276         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013339629 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.987       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0835      |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    value_loss           | 0.246       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011068143 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0245      |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    value_loss           | 0.187       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 292         |\n",
            "|    total_timesteps      | 75776       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020570815 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.077       |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    value_loss           | 0.0824      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 18.8         |\n",
            "|    ep_rew_mean          | 27.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 259          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 300          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0134146195 |\n",
            "|    clip_fraction        | 0.155        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.19        |\n",
            "|    explained_variance   | 0.99         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0476       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.0149      |\n",
            "|    value_loss           | 0.183        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 308         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015283861 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.986       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00278    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    value_loss           | 0.28        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 315         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015709875 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0295      |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.0182     |\n",
            "|    value_loss           | 0.057       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.8        |\n",
            "|    ep_rew_mean          | 27.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 323         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011338031 |\n",
            "|    clip_fraction        | 0.0958      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.986       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.143       |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.0113     |\n",
            "|    value_loss           | 0.28        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 18.8       |\n",
            "|    ep_rew_mean          | 27.8       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 259        |\n",
            "|    iterations           | 42         |\n",
            "|    time_elapsed         | 331        |\n",
            "|    total_timesteps      | 86016      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01533011 |\n",
            "|    clip_fraction        | 0.153      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.24      |\n",
            "|    explained_variance   | 0.989      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0116     |\n",
            "|    n_updates            | 410        |\n",
            "|    policy_gradient_loss | -0.0131    |\n",
            "|    value_loss           | 0.21       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 339         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011888608 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.061       |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    value_loss           | 0.135       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 259         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 347         |\n",
            "|    total_timesteps      | 90112       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015937017 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.22       |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0166      |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    value_loss           | 0.0659      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.9        |\n",
            "|    ep_rew_mean          | 27.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 258         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 355         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010127797 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0601      |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    value_loss           | 0.0911      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 18.8         |\n",
            "|    ep_rew_mean          | 27.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 363          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0107206125 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00122      |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.0145      |\n",
            "|    value_loss           | 0.104        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 18.9       |\n",
            "|    ep_rew_mean          | 27.9       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 258        |\n",
            "|    iterations           | 47         |\n",
            "|    time_elapsed         | 371        |\n",
            "|    total_timesteps      | 96256      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01496889 |\n",
            "|    clip_fraction        | 0.12       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.22      |\n",
            "|    explained_variance   | 0.989      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.14       |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | -0.0177    |\n",
            "|    value_loss           | 0.208      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 18.7       |\n",
            "|    ep_rew_mean          | 27.7       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 258        |\n",
            "|    iterations           | 48         |\n",
            "|    time_elapsed         | 379        |\n",
            "|    total_timesteps      | 98304      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01186386 |\n",
            "|    clip_fraction        | 0.14       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.19      |\n",
            "|    explained_variance   | 0.995      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.002      |\n",
            "|    n_updates            | 470        |\n",
            "|    policy_gradient_loss | -0.0136    |\n",
            "|    value_loss           | 0.0972     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 18.9         |\n",
            "|    ep_rew_mean          | 27.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 387          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0109431455 |\n",
            "|    clip_fraction        | 0.133        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.18        |\n",
            "|    explained_variance   | 0.986        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0982       |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.0152      |\n",
            "|    value_loss           | 0.277        |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fc694dce2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd4O-DwTSmAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7def640f-b124-456e-c982-410a23d0456e"
      },
      "source": [
        "episodes = 20\n",
        "n_wins=0\n",
        "for episode in range(1, episodes+1):\n",
        "    current_state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    human_play=True\n",
        "    while not done:\n",
        "        if human_play:\n",
        "          env.step(np.random.choice(np.arange(0,7)),1)\n",
        "          #print(\"Random is playing: \")\n",
        "          human_play=False\n",
        "          #print(\"Current State:\")\n",
        "          #print(current_state) \n",
        "          continue\n",
        "        else: \n",
        "          #print(\"Agent is playing: \")\n",
        "          action = model.predict(current_state)[0]\n",
        "          current_state, reward, done, info = env.step(action,-1)\n",
        "          #print(\"Current action is: \",action)\n",
        "          #print(\"Collected reward is: \",reward)\n",
        "          score+=reward\n",
        "          #print(\"Current State:\")\n",
        "          #print(current_state)  \n",
        "          human_play=True\n",
        "    if done:\n",
        "      print(\"Game was done at episode {} with a score of {}\".format(episode,score))   \n",
        "      if info[\"winner\"]==\"Agent\":\n",
        "        n_wins+=1   \n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game was done at episode 1 with a score of -29\n",
            "Episode:1 Score:-29\n",
            "Game was done at episode 2 with a score of -24\n",
            "Episode:2 Score:-24\n",
            "Game was done at episode 3 with a score of -32\n",
            "Episode:3 Score:-32\n",
            "Game was done at episode 4 with a score of -7\n",
            "Episode:4 Score:-7\n",
            "Game was done at episode 5 with a score of 9\n",
            "Episode:5 Score:9\n",
            "Game was done at episode 6 with a score of -18\n",
            "Episode:6 Score:-18\n",
            "Game was done at episode 7 with a score of -30\n",
            "Episode:7 Score:-30\n",
            "Game was done at episode 8 with a score of -57\n",
            "Episode:8 Score:-57\n",
            "Game was done at episode 9 with a score of -15\n",
            "Episode:9 Score:-15\n",
            "Game was done at episode 10 with a score of 4\n",
            "Episode:10 Score:4\n",
            "Game was done at episode 11 with a score of -19\n",
            "Episode:11 Score:-19\n",
            "Game was done at episode 12 with a score of 8\n",
            "Episode:12 Score:8\n",
            "Game was done at episode 13 with a score of -27\n",
            "Episode:13 Score:-27\n",
            "Game was done at episode 14 with a score of -23\n",
            "Episode:14 Score:-23\n",
            "Game was done at episode 15 with a score of -16\n",
            "Episode:15 Score:-16\n",
            "Game was done at episode 16 with a score of -14\n",
            "Episode:16 Score:-14\n",
            "Game was done at episode 17 with a score of -24\n",
            "Episode:17 Score:-24\n",
            "Game was done at episode 18 with a score of -19\n",
            "Episode:18 Score:-19\n",
            "Game was done at episode 19 with a score of -14\n",
            "Episode:19 Score:-14\n",
            "Game was done at episode 20 with a score of -24\n",
            "Episode:20 Score:-24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYC-IMem_cVq",
        "outputId": "4453d6f5-ebdf-424e-a2a3-cd2e45e793c0"
      },
      "source": [
        "print(\"Total iterations won by agent is: {}\".format(n_wins))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total iterations won by agent is: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mKbTEs_WyEqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fSuxC_AYyEuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oT6HlyTEyEws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bda0XyXdyEzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fl9VCuMcyE3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dTDpCNmCyE8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ara2metYyE-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IxvS9JKJyFDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZZrFvASYyFIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sejgtaPZyFM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym \n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ],
      "metadata": {
        "id": "4xiZeB-3yFR7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROWS = 6\n",
        "NUM_COLS = 7\n",
        "NUM2WIN = 4"
      ],
      "metadata": {
        "id": "wtfkvwH6zhia"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustumEnv(Env):\n",
        "    NUM_ROWS = 6\n",
        "    NUM_COLS = 7\n",
        "    NUM2WIN = 4\n",
        "    def __init__(self):\n",
        "        # Actions we can take: throw the rock in one of the 7 column\n",
        "        self.action_space = Discrete(NUM_COLS)\n",
        "        # state matrix\n",
        "        self.observation_space = Box(low=np.array([-1 for i in range(7*6)]).reshape(6,7), \n",
        "                                     high=np.array([1 for i in range(7*6)]).reshape(6,7),\n",
        "                                     dtype=np.int8)\n",
        "        # starting borad matrix\n",
        "        self.state = np.zeros((6,7))\n",
        "        \n",
        "    def step(self, action,player): \n",
        "        #action=column number\n",
        "        # Apply action\n",
        "        # throw the rock on the top of the existing/empty selected column\n",
        "        j = 0\n",
        "        #print(\"Before Action\")\n",
        "        #print(self.state)\n",
        "        #print(self.state)\n",
        "        while j + 1 < self.NUM_ROWS and self.state[j + 1][action] == 0:\n",
        "            j += 1\n",
        "        info = {}    \n",
        "        if self.state[j][action]!=0:\n",
        "          self.state[j][action]!=np.nan\n",
        "          reward=-10000\n",
        "          done=True\n",
        "          winner=\"overflow\"\n",
        "          info[\"winner\"]=winner\n",
        "          return self.state,reward,done,info\n",
        "        self.state[j][action] = player\n",
        "        #print(\"After Action\")\n",
        "        #print(self.state)\n",
        "\n",
        "        winner=\"\"\n",
        "        # reward\n",
        "        done = False\n",
        "        reward = 0\n",
        "        for i in range(self.NUM_ROWS - self.NUM2WIN + 1):\n",
        "            for j in range(self.NUM_COLS - self.NUM2WIN + 1):\n",
        "                sub_state = self.state[i:i + self.NUM2WIN, j:j + self.NUM2WIN]\n",
        "                if np.max(np.sum(sub_state, axis=0)) == self.NUM2WIN or np.max(np.sum(sub_state, axis=1)) == self.NUM2WIN or np.trace(sub_state) == self.NUM2WIN or np.trace(np.transpose(sub_state)) == self.NUM2WIN: # human having 4 consecutive pieces in a column or row or both diagonals\n",
        "                    done = True\n",
        "                    reward = -10\n",
        "                    winner=\"Human\"\n",
        "                elif np.min(np.sum(sub_state, axis=0)) == -self.NUM2WIN or np.min(np.sum(sub_state, axis=1)) == -self.NUM2WIN or np.trace(sub_state) == -self.NUM2WIN or np.trace(np.transpose(sub_state)) == -self.NUM2WIN:\n",
        "                    done = True\n",
        "                    reward = 10\n",
        "                    winner=\"Agent\"\n",
        "                \n",
        "        if -np.max(np.sum(self.state, axis=0))==np.sum(self.state[:,action]) and not done:\n",
        "                  reward=1   \n",
        "        elif not done:\n",
        "                  reward=-1\n",
        "\n",
        "                \n",
        "        \n",
        "        \n",
        "        info[\"winner\"]=winner\n",
        "        \n",
        "        # Return step information\n",
        "        return self.state, reward, done,info\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset\n",
        "        self.state = np.zeros((6,7))\n",
        "        return self.state"
      ],
      "metadata": {
        "id": "zbSD6wbtyFW-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "\n",
        "RANDOM_SEED = 5\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "env = CustumEnv()\n",
        "env.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "print(\"Action Space: {}\".format(env.action_space))\n",
        "print(\"State space: {}\".format(env.observation_space))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqfYWEoqyFaL",
        "outputId": "4a6ed7d3-849b-475d-eaa5-7e9fc6868f27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space: Discrete(7)\n",
            "State space: Box(-1, 1, (6, 7), int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# An episode a full game\n",
        "train_episodes = 250\n",
        "test_episodes = 100\n",
        "\n",
        "def agent(state_shape, action_shape):\n",
        "    \"\"\" The agent maps X-states to Y-actions\n",
        "    e.g. The neural network output is [.1, .7, .1, .3]\n",
        "    The highest value 0.7 is the Q-Value.\n",
        "    The index of the highest action (0.7) is action #1.\n",
        "    \"\"\"\n",
        "    #print(\"state_shape: \",state_shape)\n",
        "    #print(\"action shape: \",action_shape)\n",
        "    learning_rate = 0.001\n",
        "    init = tf.keras.initializers.HeUniform()\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Dense(48, input_shape=state_shape, activation='relu', kernel_initializer=init,))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "    model.add(keras.layers.Dense(16, activation='relu', kernel_initializer=init,\n",
        "    kernel_regularizer=keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
        "    bias_regularizer=keras.regularizers.l2(1e-4),\n",
        "    activity_regularizer=keras.regularizers.l2(1e-5)))\n",
        "    model.add(keras.layers.Dense(action_shape, activation='linear', kernel_initializer=init))\n",
        "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_qs(model, state, step):\n",
        "    return model.predict(state.reshape([1, state.shape[0]]))[0]\n",
        "\n",
        "def train(env, replay_memory, model, target_model, done):\n",
        "    learning_rate = 0.7 # Learning rate\n",
        "    discount_factor = 0.618\n",
        "\n",
        "    MIN_REPLAY_SIZE = 1000\n",
        "    if len(replay_memory) < MIN_REPLAY_SIZE:\n",
        "        return\n",
        "    env.reset()\n",
        "    batch_size = 64 * 2\n",
        "    mini_batch = random.sample(replay_memory, batch_size)\n",
        "    current_states = np.array([transition[0] for transition in mini_batch])\n",
        "    current_qs_list = model.predict(current_states)\n",
        "    new_current_states = np.array([transition[3] for transition in mini_batch])\n",
        "    future_qs_list = target_model.predict(new_current_states)\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for index, (observation, action, reward, new_observation, done) in enumerate(mini_batch):\n",
        "        if not done:\n",
        "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
        "        else:\n",
        "            max_future_q = reward\n",
        "\n",
        "        current_qs = current_qs_list[index]\n",
        "        try:\n",
        "          current_qs[:,action] = (1 - learning_rate) * current_qs[:,action] + learning_rate * max_future_q\n",
        "        except:\n",
        "          print(action)\n",
        "          print(current_qs.shape)\n",
        "        X.append(observation)\n",
        "        Y.append(current_qs)\n",
        "    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)"
      ],
      "metadata": {
        "id": "p-c1fZi3yTGW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1 # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
        "max_epsilon = 1 # You can't explore more than 100% of the time\n",
        "min_epsilon = 0.01 # At a minimum, we'll always explore 1% of the time\n",
        "decay = 0.01\n",
        "\n",
        "# 1. Initialize the Target and Main models\n",
        "# Main Model (updated every 4 steps)\n",
        "model = agent(env.observation_space.shape, env.action_space.n)\n",
        "# Target Model (updated every 100 steps)\n",
        "target_model = agent(env.observation_space.shape, env.action_space.n)\n",
        "target_model.set_weights(model.get_weights())\n",
        "\n",
        "replay_memory = deque(maxlen=50_000)\n",
        "\n",
        "target_update_counter = 0\n",
        "\n",
        "# X = states, y = actions\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "steps_to_update_target_model = 0\n",
        "n_wins=0\n",
        "train_list_performace=[]\n",
        "for episode in range(train_episodes):\n",
        "    total_training_rewards = 0\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    human_play=True\n",
        "    stop=100\n",
        "    \n",
        "    while not done:\n",
        "        if human_play:\n",
        "          action = np.random.choice(np.arange(0,7))\n",
        "          env.step(action,1)\n",
        "          human_play=False  \n",
        "        \n",
        "        else:\n",
        "          stop-=1\n",
        "          steps_to_update_target_model += 1\n",
        "          human_play=True\n",
        "          random_number = np.random.rand()\n",
        "          # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
        "          if random_number <= epsilon:\n",
        "              # Explore\n",
        "              action = env.action_space.sample()\n",
        "              print(\"Taking a random walk\")\n",
        "          else:\n",
        "              # Exploit best known action\n",
        "              # model dims are (batch, env.observation_space.n)\n",
        "              encoded = observation\n",
        "              #encoded_reshaped = encoded.reshape(1,encoded_reshaped[0],encoded_reshaped[1],1)\n",
        "              #print(encoded_reshaped.shape)\n",
        "              predicted = model.predict(observation)\n",
        "              #print(\"predicted: \",predicted.shape)\n",
        "              action = predicted.argmax(axis=1)[1]\n",
        "              #print(\"action: \",action)\n",
        "          temp=env.state   \n",
        "          new_observation, reward, done, info = env.step(action,-1)\n",
        "          if info[\"winner\"]==\"overflow\":\n",
        "            l=[i for i in range(env.action_space.n)]\n",
        "            l.remove(action)\n",
        "\n",
        "            action=np.random.choice(l)\n",
        "            new_observation, reward, done, info = env.step(action,-1)\n",
        "          if (temp==new_observation).all() and stop==-1:\n",
        "            print(\"Action that was taken is: \",action)\n",
        "            print(temp)\n",
        "            print(new_observation)\n",
        "          replay_memory.append([observation, action, reward, new_observation, done])\n",
        "\n",
        "          # 3. Update the Main Network using the Bellman Equation\n",
        "          if steps_to_update_target_model % 4 == 0 or done:\n",
        "              train(env, replay_memory, model, target_model, done)\n",
        "\n",
        "          observation = new_observation\n",
        "          total_training_rewards += reward\n",
        "\n",
        "          if done:\n",
        "              print('Total training rewards: {} after n steps = {} with final reward = {} with a winner :{}'.format(total_training_rewards, episode, reward,info[\"winner\"]))\n",
        "              if info[\"winner\"]==\"Agent\":\n",
        "                n_wins+=1\n",
        "              else:\n",
        "                n_wins=max(n_wins-1,0) \n",
        "              train_list_performace.append(n_wins)   \n",
        "              total_training_rewards += 1\n",
        "\n",
        "              if steps_to_update_target_model >= 100:\n",
        "                  print('Copying main network weights to the target network weights')\n",
        "                  target_model.set_weights(model.get_weights())\n",
        "                  steps_to_update_target_model = 0\n",
        "              break\n",
        "          else:\n",
        "            print(\"Training at epoch = {}, with a reward {}\".format(episode,reward))\n",
        "        \n",
        "        epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDlKsJWIy2AD",
        "outputId": "27099919-0450-4cc8-c662-f4da68d42e6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 0, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 0 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 1, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 3 after n steps = 1 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 2, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 2, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 2, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 2, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 2, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 2 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 3, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9998 after n steps = 3 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward -1\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 6, 7) for input Tensor(\"dense_input:0\", shape=(None, 6, 7), dtype=float32), but it was called on an input with incompatible shape (None, 7).\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 4, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 13 after n steps = 4 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Training at epoch = 5, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward -1\n",
            "Training at epoch = 5, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 5, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: -10010 after n steps = 5 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 6, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 13 after n steps = 6 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 7, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 0 after n steps = 7 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 8, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 8, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 8, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 8 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 9, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 8 after n steps = 9 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 10, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: -14 after n steps = 10 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 11, with a reward -1\n",
            "Training at epoch = 11, with a reward -1\n",
            "Total training rewards: -13 after n steps = 11 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Training at epoch = 12, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 12, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10002 after n steps = 12 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 13, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 13, with a reward 1\n",
            "Training at epoch = 13, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 13, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 13, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 11 after n steps = 13 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 14, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 14, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 14, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 14, with a reward 1\n",
            "Training at epoch = 14, with a reward 1\n",
            "Total training rewards: -9 after n steps = 14 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 15, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: -10009 after n steps = 15 with final reward = -10000 with a winner :overflow\n",
            "Training at epoch = 16, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 16, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 16, with a reward -1\n",
            "Training at epoch = 16, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 16, with a reward -1\n",
            "Total training rewards: 11 after n steps = 16 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward 1\n",
            "Training at epoch = 17, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 17, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 17 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward 1\n",
            "Training at epoch = 18, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward -1\n",
            "Training at epoch = 18, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 18, with a reward -1\n",
            "Training at epoch = 18, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 18 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward 1\n",
            "Training at epoch = 19, with a reward -1\n",
            "Training at epoch = 19, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 19, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 19 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 20, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10000 after n steps = 20 with final reward = -10000 with a winner :overflow\n",
            "Training at epoch = 21, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward 1\n",
            "Training at epoch = 21, with a reward -1\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 21, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10009 after n steps = 21 with final reward = -10000 with a winner :overflow\n",
            "Training at epoch = 22, with a reward 1\n",
            "Training at epoch = 22, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 22, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 22, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 22, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 22 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 23, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 23, with a reward -1\n",
            "Training at epoch = 23, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 23, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 23, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 23, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -12 after n steps = 23 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 24, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward 1\n",
            "Training at epoch = 24, with a reward 1\n",
            "Training at epoch = 24, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 24, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -14 after n steps = 24 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Training at epoch = 25, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward -1\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward -1\n",
            "Training at epoch = 25, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 25, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 11 after n steps = 25 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 26, with a reward 1\n",
            "Training at epoch = 26, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 26, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 26, with a reward -1\n",
            "Training at epoch = 26, with a reward -1\n",
            "Total training rewards: 9 after n steps = 26 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 27, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 27, with a reward -1\n",
            "Training at epoch = 27, with a reward 1\n",
            "Training at epoch = 27, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 27, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 27, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10 after n steps = 27 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward 1\n",
            "Training at epoch = 28, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward -1\n",
            "Training at epoch = 28, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 28, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 11 after n steps = 28 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 29, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 29, with a reward 1\n",
            "Training at epoch = 29, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 29, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 29, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 29, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 29, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -13 after n steps = 29 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 30, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Training at epoch = 30, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 30, with a reward -1\n",
            "Total training rewards: -10006 after n steps = 30 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 31, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 31, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 31, with a reward -1\n",
            "Training at epoch = 31, with a reward -1\n",
            "Training at epoch = 31, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 31, with a reward -1\n",
            "Training at epoch = 31, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 7 after n steps = 31 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 32, with a reward 1\n",
            "Training at epoch = 32, with a reward 1\n",
            "Training at epoch = 32, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 32, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 32, with a reward -1\n",
            "Training at epoch = 32, with a reward 1\n",
            "Training at epoch = 32, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 32, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 32, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 32, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 32 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward -1\n",
            "Training at epoch = 33, with a reward -1\n",
            "Training at epoch = 33, with a reward -1\n",
            "Training at epoch = 33, with a reward -1\n",
            "Training at epoch = 33, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 33, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 7 after n steps = 33 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 34, with a reward -1\n",
            "Total training rewards: -9 after n steps = 34 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward -1\n",
            "Training at epoch = 35, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 35, with a reward -1\n",
            "Total training rewards: 10 after n steps = 35 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 36, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward 1\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward -1\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 36, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 6 after n steps = 36 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 37, with a reward 1\n",
            "Training at epoch = 37, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 37, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 37, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 37, with a reward -1\n",
            "Training at epoch = 37, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 37, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 37, with a reward -1\n",
            "Total training rewards: 10 after n steps = 37 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 38, with a reward 1\n",
            "Training at epoch = 38, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward 1\n",
            "Training at epoch = 38, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward -1\n",
            "Training at epoch = 38, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward -1\n",
            "Training at epoch = 38, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 38, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -13 after n steps = 38 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 39, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 39, with a reward 1\n",
            "Training at epoch = 39, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 39, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 39, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 39, with a reward -1\n",
            "Total training rewards: -10 after n steps = 39 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward 1\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Training at epoch = 40, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 40, with a reward -1\n",
            "Total training rewards: -9999 after n steps = 40 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 41, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 41, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 41, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 41, with a reward 1\n",
            "Training at epoch = 41, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -7 after n steps = 41 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Training at epoch = 42, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 42, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10010 after n steps = 42 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 43, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 43, with a reward 1\n",
            "Training at epoch = 43, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 43, with a reward -1\n",
            "Training at epoch = 43, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -11 after n steps = 43 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward 1\n",
            "Training at epoch = 44, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Training at epoch = 44, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 44, with a reward -1\n",
            "Training at epoch = 44, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 6 after n steps = 44 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 45, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 45, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 45, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 45, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 45, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 45 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward -1\n",
            "Training at epoch = 46, with a reward 1\n",
            "Training at epoch = 46, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward -1\n",
            "Training at epoch = 46, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 46, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 46 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward 1\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Training at epoch = 47, with a reward 1\n",
            "Training at epoch = 47, with a reward -1\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 47, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10006 after n steps = 47 with final reward = -10000 with a winner :overflow\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 48, with a reward 1\n",
            "Training at epoch = 48, with a reward -1\n",
            "Training at epoch = 48, with a reward -1\n",
            "Total training rewards: 9 after n steps = 48 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 49, with a reward 1\n",
            "Training at epoch = 49, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 49, with a reward -1\n",
            "Training at epoch = 49, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 49, with a reward -1\n",
            "Total training rewards: 7 after n steps = 49 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 50, with a reward 1\n",
            "Training at epoch = 50, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 50, with a reward 1\n",
            "Training at epoch = 50, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 50 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 51, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 51, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 51, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 51, with a reward 1\n",
            "Training at epoch = 51, with a reward -1\n",
            "Total training rewards: 13 after n steps = 51 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 52, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 52, with a reward -1\n",
            "Training at epoch = 52, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 52, with a reward -1\n",
            "Training at epoch = 52, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 52, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 52, with a reward -1\n",
            "Total training rewards: 7 after n steps = 52 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 53, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 53, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 53, with a reward -1\n",
            "Training at epoch = 53, with a reward 1\n",
            "Training at epoch = 53, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 11 after n steps = 53 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Training at epoch = 54, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Training at epoch = 54, with a reward 1\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 54, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 5 after n steps = 54 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward -1\n",
            "Training at epoch = 55, with a reward 1\n",
            "Training at epoch = 55, with a reward -1\n",
            "Training at epoch = 55, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 55, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -12 after n steps = 55 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 56, with a reward 1\n",
            "Training at epoch = 56, with a reward -1\n",
            "Training at epoch = 56, with a reward 1\n",
            "Training at epoch = 56, with a reward -1\n",
            "Total training rewards: 10 after n steps = 56 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 57, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Training at epoch = 57, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Training at epoch = 57, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 57, with a reward -1\n",
            "Training at epoch = 57, with a reward -1\n",
            "Training at epoch = 57, with a reward 1\n",
            "Total training rewards: 5 after n steps = 57 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 58, with a reward 1\n",
            "Training at epoch = 58, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 58, with a reward -1\n",
            "Training at epoch = 58, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 58, with a reward -1\n",
            "Total training rewards: 7 after n steps = 58 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward 1\n",
            "Training at epoch = 59, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 59, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 59 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 60, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 60, with a reward -1\n",
            "Training at epoch = 60, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 60, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 60, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -13 after n steps = 60 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 61, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 61, with a reward 1\n",
            "Training at epoch = 61, with a reward 1\n",
            "Training at epoch = 61, with a reward -1\n",
            "Training at epoch = 61, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 61, with a reward -1\n",
            "Total training rewards: 10 after n steps = 61 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 62, with a reward 1\n",
            "Training at epoch = 62, with a reward 1\n",
            "Training at epoch = 62, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 62, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 62, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -11 after n steps = 62 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 63, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 63, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 63, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 63, with a reward 1\n",
            "Training at epoch = 63, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 63, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 63 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 64, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 64, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 64, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 64, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 64, with a reward 1\n",
            "Training at epoch = 64, with a reward -1\n",
            "Total training rewards: 10 after n steps = 64 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 65, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 65, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 65, with a reward 1\n",
            "Training at epoch = 65, with a reward 1\n",
            "Training at epoch = 65, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 15 after n steps = 65 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 66, with a reward 1\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 66, with a reward -1\n",
            "Training at epoch = 66, with a reward 1\n",
            "Training at epoch = 66, with a reward 1\n",
            "Training at epoch = 66, with a reward 1\n",
            "Training at epoch = 66, with a reward -1\n",
            "Total training rewards: 7 after n steps = 66 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 67, with a reward 1\n",
            "Training at epoch = 67, with a reward 1\n",
            "Training at epoch = 67, with a reward 1\n",
            "Training at epoch = 67, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -8 after n steps = 67 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 68, with a reward 1\n",
            "Training at epoch = 68, with a reward -1\n",
            "Training at epoch = 68, with a reward -1\n",
            "Total training rewards: 9 after n steps = 68 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 69, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 69, with a reward 1\n",
            "Training at epoch = 69, with a reward 1\n",
            "Total training rewards: 13 after n steps = 69 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 70, with a reward 1\n",
            "Training at epoch = 70, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 70, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 70, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 70, with a reward -1\n",
            "Training at epoch = 70, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 70, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 7 after n steps = 70 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 71, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 71, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 71, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 71, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 71, with a reward -1\n",
            "Training at epoch = 71, with a reward -1\n",
            "Total training rewards: 6 after n steps = 71 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 72, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward 1\n",
            "Training at epoch = 72, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 72, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -15 after n steps = 72 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 73, with a reward 1\n",
            "Training at epoch = 73, with a reward 1\n",
            "Training at epoch = 73, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 73, with a reward -1\n",
            "Training at epoch = 73, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 73, with a reward -1\n",
            "Training at epoch = 73, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 73, with a reward -1\n",
            "Training at epoch = 73, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 5 after n steps = 73 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 74, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 74, with a reward 1\n",
            "Training at epoch = 74, with a reward 1\n",
            "Training at epoch = 74, with a reward -1\n",
            "Training at epoch = 74, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 74, with a reward 1\n",
            "Total training rewards: -8 after n steps = 74 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward 1\n",
            "Training at epoch = 75, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 75, with a reward -1\n",
            "Total training rewards: 14 after n steps = 75 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 76, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 76, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 76, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 76, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 76, with a reward -1\n",
            "Training at epoch = 76, with a reward -1\n",
            "Training at epoch = 76, with a reward -1\n",
            "Total training rewards: 9 after n steps = 76 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 77, with a reward 1\n",
            "Training at epoch = 77, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 77, with a reward -1\n",
            "Total training rewards: 9 after n steps = 77 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 78, with a reward 1\n",
            "Training at epoch = 78, with a reward 1\n",
            "Training at epoch = 78, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 78, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 78, with a reward -1\n",
            "Training at epoch = 78, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 78 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 79, with a reward 1\n",
            "Training at epoch = 79, with a reward 1\n",
            "Training at epoch = 79, with a reward 1\n",
            "Total training rewards: 13 after n steps = 79 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 80, with a reward 1\n",
            "Training at epoch = 80, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 80, with a reward -1\n",
            "Training at epoch = 80, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 80, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 80, with a reward -1\n",
            "Training at epoch = 80, with a reward 1\n",
            "Training at epoch = 80, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 80, with a reward 1\n",
            "Training at epoch = 80, with a reward -1\n",
            "Total training rewards: 10 after n steps = 80 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 81, with a reward 1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 81, with a reward -1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 81, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 81, with a reward 1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Training at epoch = 81, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10007 after n steps = 81 with final reward = -10000 with a winner :overflow\n",
            "Training at epoch = 82, with a reward 1\n",
            "Training at epoch = 82, with a reward -1\n",
            "Training at epoch = 82, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 82, with a reward -1\n",
            "Total training rewards: 8 after n steps = 82 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 83, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 83, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 83, with a reward -1\n",
            "Training at epoch = 83, with a reward -1\n",
            "Training at epoch = 83, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 83, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 83, with a reward -1\n",
            "Training at epoch = 83, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 6 after n steps = 83 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 84, with a reward 1\n",
            "Training at epoch = 84, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 84, with a reward -1\n",
            "Total training rewards: 9 after n steps = 84 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 85, with a reward 1\n",
            "Training at epoch = 85, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward -1\n",
            "Training at epoch = 85, with a reward 1\n",
            "Training at epoch = 85, with a reward -1\n",
            "Training at epoch = 85, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward -1\n",
            "Training at epoch = 85, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 85, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 10 after n steps = 85 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 86, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 86, with a reward 1\n",
            "Training at epoch = 86, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 86, with a reward -1\n",
            "Training at epoch = 86, with a reward 1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 86, with a reward 1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 86, with a reward -1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Training at epoch = 86, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 86, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -10004 after n steps = 86 with final reward = -10000 with a winner :overflow\n",
            "Taking a random walk\n",
            "Training at epoch = 87, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 87, with a reward 1\n",
            "Training at epoch = 87, with a reward -1\n",
            "Training at epoch = 87, with a reward 1\n",
            "Training at epoch = 87, with a reward -1\n",
            "Training at epoch = 87, with a reward 1\n",
            "Training at epoch = 87, with a reward 1\n",
            "Training at epoch = 87, with a reward -1\n",
            "Training at epoch = 87, with a reward -1\n",
            "Training at epoch = 87, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 87, with a reward -1\n",
            "Training at epoch = 87, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 87, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -11 after n steps = 87 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 88, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 88, with a reward 1\n",
            "Training at epoch = 88, with a reward -1\n",
            "Training at epoch = 88, with a reward 1\n",
            "Training at epoch = 88, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 88, with a reward -1\n",
            "Training at epoch = 88, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 88, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 88, with a reward -1\n",
            "Training at epoch = 88, with a reward -1\n",
            "Training at epoch = 88, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -13 after n steps = 88 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 89, with a reward 1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 89, with a reward 1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 89, with a reward -1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Training at epoch = 89, with a reward -1\n",
            "Total training rewards: 5 after n steps = 89 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 90, with a reward 1\n",
            "Training at epoch = 90, with a reward 1\n",
            "Training at epoch = 90, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 90, with a reward -1\n",
            "Total training rewards: 10 after n steps = 90 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 91, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 91, with a reward 1\n",
            "Training at epoch = 91, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 91, with a reward -1\n",
            "Training at epoch = 91, with a reward 1\n",
            "Training at epoch = 91, with a reward 1\n",
            "Total training rewards: 12 after n steps = 91 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 92, with a reward 1\n",
            "Training at epoch = 92, with a reward 1\n",
            "Training at epoch = 92, with a reward -1\n",
            "Training at epoch = 92, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 92, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -11 after n steps = 92 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 93, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 93, with a reward -1\n",
            "Training at epoch = 93, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 93, with a reward 1\n",
            "Total training rewards: -10 after n steps = 93 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 94, with a reward 1\n",
            "Training at epoch = 94, with a reward 1\n",
            "Training at epoch = 94, with a reward -1\n",
            "Training at epoch = 94, with a reward -1\n",
            "Total training rewards: -10 after n steps = 94 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 95, with a reward 1\n",
            "Training at epoch = 95, with a reward 1\n",
            "Training at epoch = 95, with a reward -1\n",
            "Total training rewards: 11 after n steps = 95 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 96, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 96, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 96, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 96, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 96, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 96 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 97, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 97, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 97, with a reward -1\n",
            "Training at epoch = 97, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 97, with a reward -1\n",
            "Total training rewards: 9 after n steps = 97 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 98, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 98, with a reward 1\n",
            "Training at epoch = 98, with a reward 1\n",
            "Training at epoch = 98, with a reward 1\n",
            "Total training rewards: 14 after n steps = 98 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 99, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 99, with a reward -1\n",
            "Training at epoch = 99, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 99, with a reward -1\n",
            "Total training rewards: 8 after n steps = 99 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 100, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 100, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 100, with a reward -1\n",
            "Training at epoch = 100, with a reward -1\n",
            "Training at epoch = 100, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 100, with a reward 1\n",
            "Training at epoch = 100, with a reward -1\n",
            "Training at epoch = 100, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 100, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 100 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 101, with a reward 1\n",
            "Training at epoch = 101, with a reward 1\n",
            "Training at epoch = 101, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 101, with a reward 1\n",
            "Training at epoch = 101, with a reward 1\n",
            "Training at epoch = 101, with a reward -1\n",
            "Training at epoch = 101, with a reward -1\n",
            "Total training rewards: 11 after n steps = 101 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 102, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 102, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 102, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 102, with a reward -1\n",
            "Total training rewards: 8 after n steps = 102 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 103, with a reward 1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Training at epoch = 103, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -18 after n steps = 103 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 104, with a reward 1\n",
            "Training at epoch = 104, with a reward 1\n",
            "Training at epoch = 104, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 104, with a reward -1\n",
            "Training at epoch = 104, with a reward -1\n",
            "Total training rewards: -9 after n steps = 104 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 105, with a reward 1\n",
            "Training at epoch = 105, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 105, with a reward 1\n",
            "Training at epoch = 105, with a reward -1\n",
            "Total training rewards: 10 after n steps = 105 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 106, with a reward 1\n",
            "Training at epoch = 106, with a reward -1\n",
            "Training at epoch = 106, with a reward 1\n",
            "Training at epoch = 106, with a reward 1\n",
            "Total training rewards: 12 after n steps = 106 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 107, with a reward 1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 107, with a reward 1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Training at epoch = 107, with a reward -1\n",
            "Total training rewards: 6 after n steps = 107 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 108, with a reward 1\n",
            "Training at epoch = 108, with a reward 1\n",
            "Training at epoch = 108, with a reward -1\n",
            "Training at epoch = 108, with a reward -1\n",
            "Training at epoch = 108, with a reward -1\n",
            "Training at epoch = 108, with a reward 1\n",
            "Training at epoch = 108, with a reward 1\n",
            "Total training rewards: 11 after n steps = 108 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 109, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 109, with a reward 1\n",
            "Training at epoch = 109, with a reward -1\n",
            "Training at epoch = 109, with a reward -1\n",
            "Total training rewards: 10 after n steps = 109 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward 1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Training at epoch = 110, with a reward -1\n",
            "Total training rewards: 15 after n steps = 110 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 111, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward 1\n",
            "Training at epoch = 111, with a reward -1\n",
            "Total training rewards: 13 after n steps = 111 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 112, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 112, with a reward -1\n",
            "Training at epoch = 112, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 112, with a reward -1\n",
            "Training at epoch = 112, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 112, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 112, with a reward -1\n",
            "Training at epoch = 112, with a reward -1\n",
            "Training at epoch = 112, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 112, with a reward -1\n",
            "Training at epoch = 112, with a reward -1\n",
            "Total training rewards: 7 after n steps = 112 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward 1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Training at epoch = 113, with a reward -1\n",
            "Total training rewards: 11 after n steps = 113 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward 1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Training at epoch = 114, with a reward -1\n",
            "Total training rewards: 7 after n steps = 114 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward 1\n",
            "Training at epoch = 115, with a reward -1\n",
            "Training at epoch = 115, with a reward -1\n",
            "Total training rewards: 15 after n steps = 115 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward -1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward 1\n",
            "Training at epoch = 116, with a reward -1\n",
            "Total training rewards: 13 after n steps = 116 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward 1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Training at epoch = 117, with a reward -1\n",
            "Total training rewards: 5 after n steps = 117 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 118, with a reward 1\n",
            "Training at epoch = 118, with a reward 1\n",
            "Training at epoch = 118, with a reward 1\n",
            "Total training rewards: 13 after n steps = 118 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward 1\n",
            "Training at epoch = 119, with a reward -1\n",
            "Training at epoch = 119, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward 1\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward 1\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward -1\n",
            "Training at epoch = 119, with a reward -1\n",
            "Training at epoch = 119, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 119, with a reward -1\n",
            "Training at epoch = 119, with a reward 1\n",
            "Training at epoch = 119, with a reward 1\n",
            "Training at epoch = 119, with a reward -1\n",
            "Training at epoch = 119, with a reward -1\n",
            "Total training rewards: 13 after n steps = 119 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 120, with a reward 1\n",
            "Training at epoch = 120, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 120, with a reward 1\n",
            "Training at epoch = 120, with a reward 1\n",
            "Training at epoch = 120, with a reward 1\n",
            "Training at epoch = 120, with a reward -1\n",
            "Training at epoch = 120, with a reward -1\n",
            "Total training rewards: -9 after n steps = 120 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward 1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Training at epoch = 121, with a reward -1\n",
            "Total training rewards: 29 after n steps = 121 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward 1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Training at epoch = 122, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 17 after n steps = 122 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 123, with a reward 1\n",
            "Training at epoch = 123, with a reward -1\n",
            "Training at epoch = 123, with a reward -1\n",
            "Total training rewards: 9 after n steps = 123 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward 1\n",
            "Training at epoch = 124, with a reward -1\n",
            "Total training rewards: 25 after n steps = 124 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 125, with a reward 1\n",
            "Training at epoch = 125, with a reward -1\n",
            "Training at epoch = 125, with a reward -1\n",
            "Total training rewards: 9 after n steps = 125 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 126, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 126, with a reward -1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 126, with a reward -1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 126, with a reward 1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Training at epoch = 126, with a reward 1\n",
            "Training at epoch = 126, with a reward -1\n",
            "Total training rewards: 15 after n steps = 126 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 127, with a reward 1\n",
            "Training at epoch = 127, with a reward 1\n",
            "Training at epoch = 127, with a reward -1\n",
            "Total training rewards: 11 after n steps = 127 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 128, with a reward 1\n",
            "Training at epoch = 128, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 128, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 128, with a reward -1\n",
            "Training at epoch = 128, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 128, with a reward 1\n",
            "Training at epoch = 128, with a reward 1\n",
            "Training at epoch = 128, with a reward -1\n",
            "Training at epoch = 128, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 128, with a reward -1\n",
            "Training at epoch = 128, with a reward -1\n",
            "Total training rewards: 11 after n steps = 128 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward 1\n",
            "Training at epoch = 129, with a reward -1\n",
            "Total training rewards: 13 after n steps = 129 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 130, with a reward 1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 130, with a reward -1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 130, with a reward 1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Training at epoch = 130, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 130, with a reward -1\n",
            "Training at epoch = 130, with a reward -1\n",
            "Total training rewards: 15 after n steps = 130 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 131, with a reward 1\n",
            "Training at epoch = 131, with a reward -1\n",
            "Training at epoch = 131, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 131, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 131, with a reward 1\n",
            "Training at epoch = 131, with a reward 1\n",
            "Training at epoch = 131, with a reward -1\n",
            "Training at epoch = 131, with a reward -1\n",
            "Training at epoch = 131, with a reward 1\n",
            "Training at epoch = 131, with a reward 1\n",
            "Training at epoch = 131, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 9 after n steps = 131 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 132, with a reward 1\n",
            "Training at epoch = 132, with a reward -1\n",
            "Training at epoch = 132, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 132, with a reward -1\n",
            "Training at epoch = 132, with a reward 1\n",
            "Training at epoch = 132, with a reward -1\n",
            "Training at epoch = 132, with a reward -1\n",
            "Total training rewards: 7 after n steps = 132 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 133, with a reward 1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 133, with a reward -1\n",
            "Training at epoch = 133, with a reward 1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 133, with a reward -1\n",
            "Training at epoch = 133, with a reward 1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Training at epoch = 133, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 5 after n steps = 133 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 134, with a reward 1\n",
            "Training at epoch = 134, with a reward -1\n",
            "Training at epoch = 134, with a reward -1\n",
            "Total training rewards: 9 after n steps = 134 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward 1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Training at epoch = 135, with a reward -1\n",
            "Total training rewards: 11 after n steps = 135 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 136, with a reward 1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 136, with a reward 1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Training at epoch = 136, with a reward 1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 136, with a reward 1\n",
            "Training at epoch = 136, with a reward -1\n",
            "Training at epoch = 136, with a reward 1\n",
            "Total training rewards: -11 after n steps = 136 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 137, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward -1\n",
            "Training at epoch = 137, with a reward -1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 137, with a reward -1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward -1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward 1\n",
            "Training at epoch = 137, with a reward -1\n",
            "Total training rewards: 21 after n steps = 137 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Training at epoch = 138, with a reward 1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Training at epoch = 138, with a reward -1\n",
            "Total training rewards: 9 after n steps = 138 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 139, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward -1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Training at epoch = 139, with a reward 1\n",
            "Taking a random walk\n",
            "Total training rewards: 13 after n steps = 139 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward 1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Training at epoch = 140, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 19 after n steps = 140 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 141, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward 1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Training at epoch = 141, with a reward -1\n",
            "Total training rewards: 9 after n steps = 141 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 142, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 142, with a reward -1\n",
            "Training at epoch = 142, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 142, with a reward -1\n",
            "Training at epoch = 142, with a reward 1\n",
            "Training at epoch = 142, with a reward -1\n",
            "Training at epoch = 142, with a reward -1\n",
            "Total training rewards: 7 after n steps = 142 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 143, with a reward 1\n",
            "Training at epoch = 143, with a reward 1\n",
            "Training at epoch = 143, with a reward -1\n",
            "Training at epoch = 143, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 143, with a reward 1\n",
            "Training at epoch = 143, with a reward 1\n",
            "Training at epoch = 143, with a reward -1\n",
            "Training at epoch = 143, with a reward -1\n",
            "Training at epoch = 143, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 143, with a reward 1\n",
            "Training at epoch = 143, with a reward -1\n",
            "Total training rewards: 11 after n steps = 143 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 144, with a reward 1\n",
            "Training at epoch = 144, with a reward -1\n",
            "Training at epoch = 144, with a reward -1\n",
            "Total training rewards: 9 after n steps = 144 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward -1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Training at epoch = 145, with a reward 1\n",
            "Total training rewards: 7 after n steps = 145 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 146, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 146, with a reward 1\n",
            "Training at epoch = 146, with a reward -1\n",
            "Training at epoch = 146, with a reward 1\n",
            "Training at epoch = 146, with a reward 1\n",
            "Training at epoch = 146, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 146, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: 11 after n steps = 146 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 147, with a reward 1\n",
            "Training at epoch = 147, with a reward -1\n",
            "Training at epoch = 147, with a reward -1\n",
            "Training at epoch = 147, with a reward -1\n",
            "Training at epoch = 147, with a reward 1\n",
            "Training at epoch = 147, with a reward -1\n",
            "Training at epoch = 147, with a reward -1\n",
            "Total training rewards: 7 after n steps = 147 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 148, with a reward 1\n",
            "Training at epoch = 148, with a reward -1\n",
            "Training at epoch = 148, with a reward -1\n",
            "Total training rewards: 9 after n steps = 148 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 149, with a reward 1\n",
            "Training at epoch = 149, with a reward -1\n",
            "Training at epoch = 149, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -11 after n steps = 149 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 150, with a reward 1\n",
            "Training at epoch = 150, with a reward 1\n",
            "Training at epoch = 150, with a reward 1\n",
            "Total training rewards: 13 after n steps = 150 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward 1\n",
            "Training at epoch = 151, with a reward -1\n",
            "Total training rewards: 15 after n steps = 151 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 152, with a reward 1\n",
            "Training at epoch = 152, with a reward 1\n",
            "Training at epoch = 152, with a reward -1\n",
            "Total training rewards: 11 after n steps = 152 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 153, with a reward 1\n",
            "Training at epoch = 153, with a reward 1\n",
            "Training at epoch = 153, with a reward -1\n",
            "Total training rewards: 11 after n steps = 153 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 154, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 154, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 154, with a reward -1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward 1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Training at epoch = 154, with a reward -1\n",
            "Total training rewards: 11 after n steps = 154 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 155, with a reward 1\n",
            "Training at epoch = 155, with a reward -1\n",
            "Training at epoch = 155, with a reward -1\n",
            "Total training rewards: 9 after n steps = 155 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 156, with a reward 1\n",
            "Training at epoch = 156, with a reward -1\n",
            "Training at epoch = 156, with a reward -1\n",
            "Total training rewards: 9 after n steps = 156 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 157, with a reward -1\n",
            "Training at epoch = 157, with a reward -1\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward 1\n",
            "Training at epoch = 157, with a reward -1\n",
            "Training at epoch = 157, with a reward -1\n",
            "Total training rewards: 11 after n steps = 157 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 158, with a reward 1\n",
            "Training at epoch = 158, with a reward -1\n",
            "Training at epoch = 158, with a reward -1\n",
            "Total training rewards: 9 after n steps = 158 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 159, with a reward 1\n",
            "Training at epoch = 159, with a reward -1\n",
            "Training at epoch = 159, with a reward -1\n",
            "Total training rewards: 9 after n steps = 159 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 160, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 160, with a reward 1\n",
            "Training at epoch = 160, with a reward -1\n",
            "Total training rewards: -9 after n steps = 160 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 161, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 161, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward 1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Training at epoch = 161, with a reward -1\n",
            "Total training rewards: 7 after n steps = 161 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 162, with a reward 1\n",
            "Training at epoch = 162, with a reward 1\n",
            "Training at epoch = 162, with a reward 1\n",
            "Training at epoch = 162, with a reward 1\n",
            "Training at epoch = 162, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 162, with a reward 1\n",
            "Training at epoch = 162, with a reward -1\n",
            "Total training rewards: 15 after n steps = 162 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward 1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Training at epoch = 163, with a reward -1\n",
            "Total training rewards: 9 after n steps = 163 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 164, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 164, with a reward 1\n",
            "Training at epoch = 164, with a reward -1\n",
            "Training at epoch = 164, with a reward -1\n",
            "Training at epoch = 164, with a reward 1\n",
            "Training at epoch = 164, with a reward 1\n",
            "Training at epoch = 164, with a reward -1\n",
            "Total training rewards: 11 after n steps = 164 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 165, with a reward 1\n",
            "Training at epoch = 165, with a reward 1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 165, with a reward 1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward 1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Training at epoch = 165, with a reward -1\n",
            "Total training rewards: 7 after n steps = 165 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 166, with a reward 1\n",
            "Training at epoch = 166, with a reward -1\n",
            "Training at epoch = 166, with a reward 1\n",
            "Training at epoch = 166, with a reward -1\n",
            "Training at epoch = 166, with a reward 1\n",
            "Training at epoch = 166, with a reward -1\n",
            "Training at epoch = 166, with a reward -1\n",
            "Total training rewards: 9 after n steps = 166 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 167, with a reward 1\n",
            "Training at epoch = 167, with a reward 1\n",
            "Training at epoch = 167, with a reward -1\n",
            "Training at epoch = 167, with a reward -1\n",
            "Training at epoch = 167, with a reward 1\n",
            "Training at epoch = 167, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 167, with a reward -1\n",
            "Total training rewards: 9 after n steps = 167 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward 1\n",
            "Training at epoch = 168, with a reward -1\n",
            "Total training rewards: 11 after n steps = 168 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 169, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 169, with a reward 1\n",
            "Training at epoch = 169, with a reward -1\n",
            "Training at epoch = 169, with a reward 1\n",
            "Training at epoch = 169, with a reward 1\n",
            "Training at epoch = 169, with a reward 1\n",
            "Training at epoch = 169, with a reward -1\n",
            "Total training rewards: 13 after n steps = 169 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 170, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward -1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward -1\n",
            "Training at epoch = 170, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward -1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 170, with a reward -1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward 1\n",
            "Training at epoch = 170, with a reward -1\n",
            "Total training rewards: 17 after n steps = 170 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 171, with a reward 1\n",
            "Training at epoch = 171, with a reward -1\n",
            "Training at epoch = 171, with a reward -1\n",
            "Total training rewards: -11 after n steps = 171 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 172, with a reward 1\n",
            "Training at epoch = 172, with a reward -1\n",
            "Training at epoch = 172, with a reward -1\n",
            "Training at epoch = 172, with a reward -1\n",
            "Training at epoch = 172, with a reward 1\n",
            "Training at epoch = 172, with a reward -1\n",
            "Training at epoch = 172, with a reward -1\n",
            "Total training rewards: 7 after n steps = 172 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 173, with a reward 1\n",
            "Training at epoch = 173, with a reward -1\n",
            "Training at epoch = 173, with a reward -1\n",
            "Total training rewards: 9 after n steps = 173 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 174, with a reward 1\n",
            "Training at epoch = 174, with a reward 1\n",
            "Training at epoch = 174, with a reward -1\n",
            "Training at epoch = 174, with a reward -1\n",
            "Training at epoch = 174, with a reward 1\n",
            "Training at epoch = 174, with a reward -1\n",
            "Training at epoch = 174, with a reward -1\n",
            "Total training rewards: 9 after n steps = 174 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 175, with a reward 1\n",
            "Training at epoch = 175, with a reward -1\n",
            "Training at epoch = 175, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 175, with a reward -1\n",
            "Training at epoch = 175, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 175, with a reward -1\n",
            "Training at epoch = 175, with a reward 1\n",
            "Training at epoch = 175, with a reward -1\n",
            "Training at epoch = 175, with a reward 1\n",
            "Training at epoch = 175, with a reward -1\n",
            "Training at epoch = 175, with a reward -1\n",
            "Total training rewards: 7 after n steps = 175 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 176, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 176, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 176, with a reward -1\n",
            "Training at epoch = 176, with a reward -1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward -1\n",
            "Training at epoch = 176, with a reward -1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 176, with a reward -1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward 1\n",
            "Training at epoch = 176, with a reward -1\n",
            "Total training rewards: 15 after n steps = 176 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward 1\n",
            "Training at epoch = 177, with a reward -1\n",
            "Total training rewards: 7 after n steps = 177 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward 1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Training at epoch = 178, with a reward -1\n",
            "Total training rewards: -9 after n steps = 178 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 179, with a reward 1\n",
            "Training at epoch = 179, with a reward -1\n",
            "Training at epoch = 179, with a reward -1\n",
            "Total training rewards: 9 after n steps = 179 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 180, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 180, with a reward 1\n",
            "Training at epoch = 180, with a reward -1\n",
            "Training at epoch = 180, with a reward -1\n",
            "Training at epoch = 180, with a reward 1\n",
            "Training at epoch = 180, with a reward -1\n",
            "Training at epoch = 180, with a reward -1\n",
            "Total training rewards: 9 after n steps = 180 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 181, with a reward 1\n",
            "Training at epoch = 181, with a reward -1\n",
            "Training at epoch = 181, with a reward -1\n",
            "Total training rewards: 9 after n steps = 181 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 182, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 182, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 182, with a reward -1\n",
            "Training at epoch = 182, with a reward -1\n",
            "Training at epoch = 182, with a reward 1\n",
            "Training at epoch = 182, with a reward -1\n",
            "Training at epoch = 182, with a reward -1\n",
            "Total training rewards: 7 after n steps = 182 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 183, with a reward 1\n",
            "Training at epoch = 183, with a reward -1\n",
            "Training at epoch = 183, with a reward -1\n",
            "Total training rewards: 9 after n steps = 183 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 184, with a reward 1\n",
            "Training at epoch = 184, with a reward -1\n",
            "Training at epoch = 184, with a reward -1\n",
            "Total training rewards: 9 after n steps = 184 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 185, with a reward 1\n",
            "Training at epoch = 185, with a reward 1\n",
            "Training at epoch = 185, with a reward -1\n",
            "Total training rewards: 11 after n steps = 185 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 186, with a reward 1\n",
            "Training at epoch = 186, with a reward 1\n",
            "Training at epoch = 186, with a reward -1\n",
            "Training at epoch = 186, with a reward -1\n",
            "Training at epoch = 186, with a reward 1\n",
            "Training at epoch = 186, with a reward -1\n",
            "Training at epoch = 186, with a reward -1\n",
            "Total training rewards: -11 after n steps = 186 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 187, with a reward 1\n",
            "Training at epoch = 187, with a reward -1\n",
            "Training at epoch = 187, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 187, with a reward -1\n",
            "Training at epoch = 187, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 187, with a reward 1\n",
            "Training at epoch = 187, with a reward 1\n",
            "Training at epoch = 187, with a reward 1\n",
            "Training at epoch = 187, with a reward 1\n",
            "Training at epoch = 187, with a reward -1\n",
            "Training at epoch = 187, with a reward -1\n",
            "Total training rewards: 11 after n steps = 187 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 188, with a reward 1\n",
            "Training at epoch = 188, with a reward 1\n",
            "Training at epoch = 188, with a reward 1\n",
            "Training at epoch = 188, with a reward -1\n",
            "Training at epoch = 188, with a reward 1\n",
            "Training at epoch = 188, with a reward -1\n",
            "Training at epoch = 188, with a reward -1\n",
            "Total training rewards: 11 after n steps = 188 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward 1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Training at epoch = 189, with a reward -1\n",
            "Total training rewards: 5 after n steps = 189 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 190, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 190, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 190, with a reward -1\n",
            "Training at epoch = 190, with a reward 1\n",
            "Training at epoch = 190, with a reward 1\n",
            "Training at epoch = 190, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 190, with a reward -1\n",
            "Training at epoch = 190, with a reward -1\n",
            "Training at epoch = 190, with a reward 1\n",
            "Training at epoch = 190, with a reward -1\n",
            "Training at epoch = 190, with a reward -1\n",
            "Total training rewards: 11 after n steps = 190 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 191, with a reward 1\n",
            "Training at epoch = 191, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 191, with a reward -1\n",
            "Total training rewards: 9 after n steps = 191 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 192, with a reward 1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 192, with a reward -1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Training at epoch = 192, with a reward 1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 192, with a reward -1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Training at epoch = 192, with a reward 1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Training at epoch = 192, with a reward -1\n",
            "Total training rewards: 5 after n steps = 192 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 193, with a reward 1\n",
            "Training at epoch = 193, with a reward -1\n",
            "Training at epoch = 193, with a reward -1\n",
            "Total training rewards: 9 after n steps = 193 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 194, with a reward 1\n",
            "Training at epoch = 194, with a reward 1\n",
            "Training at epoch = 194, with a reward -1\n",
            "Total training rewards: 11 after n steps = 194 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 195, with a reward 1\n",
            "Training at epoch = 195, with a reward -1\n",
            "Training at epoch = 195, with a reward -1\n",
            "Total training rewards: 9 after n steps = 195 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 196, with a reward 1\n",
            "Training at epoch = 196, with a reward -1\n",
            "Training at epoch = 196, with a reward -1\n",
            "Training at epoch = 196, with a reward -1\n",
            "Training at epoch = 196, with a reward 1\n",
            "Training at epoch = 196, with a reward -1\n",
            "Training at epoch = 196, with a reward -1\n",
            "Total training rewards: 7 after n steps = 196 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward 1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Training at epoch = 197, with a reward -1\n",
            "Total training rewards: -5 after n steps = 197 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 198, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward 1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Training at epoch = 198, with a reward -1\n",
            "Total training rewards: -15 after n steps = 198 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward 1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Training at epoch = 199, with a reward -1\n",
            "Total training rewards: 11 after n steps = 199 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 200, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward 1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Training at epoch = 200, with a reward -1\n",
            "Total training rewards: 15 after n steps = 200 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 201, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 201, with a reward 1\n",
            "Training at epoch = 201, with a reward -1\n",
            "Training at epoch = 201, with a reward -1\n",
            "Training at epoch = 201, with a reward 1\n",
            "Training at epoch = 201, with a reward -1\n",
            "Training at epoch = 201, with a reward -1\n",
            "Total training rewards: 9 after n steps = 201 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 202, with a reward 1\n",
            "Training at epoch = 202, with a reward -1\n",
            "Training at epoch = 202, with a reward -1\n",
            "Total training rewards: 9 after n steps = 202 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 203, with a reward 1\n",
            "Training at epoch = 203, with a reward -1\n",
            "Training at epoch = 203, with a reward -1\n",
            "Total training rewards: 9 after n steps = 203 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward 1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Training at epoch = 204, with a reward -1\n",
            "Total training rewards: 7 after n steps = 204 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Training at epoch = 205, with a reward -1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Training at epoch = 205, with a reward 1\n",
            "Total training rewards: 13 after n steps = 205 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 206, with a reward 1\n",
            "Training at epoch = 206, with a reward 1\n",
            "Training at epoch = 206, with a reward -1\n",
            "Total training rewards: 11 after n steps = 206 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 207, with a reward 1\n",
            "Training at epoch = 207, with a reward -1\n",
            "Training at epoch = 207, with a reward -1\n",
            "Training at epoch = 207, with a reward -1\n",
            "Training at epoch = 207, with a reward 1\n",
            "Training at epoch = 207, with a reward -1\n",
            "Training at epoch = 207, with a reward -1\n",
            "Total training rewards: 7 after n steps = 207 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 208, with a reward 1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 208, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 208, with a reward 1\n",
            "Training at epoch = 208, with a reward 1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward 1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward 1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Training at epoch = 208, with a reward -1\n",
            "Total training rewards: 5 after n steps = 208 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 209, with a reward 1\n",
            "Training at epoch = 209, with a reward 1\n",
            "Training at epoch = 209, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 209, with a reward -1\n",
            "Training at epoch = 209, with a reward 1\n",
            "Training at epoch = 209, with a reward -1\n",
            "Training at epoch = 209, with a reward -1\n",
            "Total training rewards: -9 after n steps = 209 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 210, with a reward 1\n",
            "Training at epoch = 210, with a reward -1\n",
            "Training at epoch = 210, with a reward -1\n",
            "Total training rewards: 9 after n steps = 210 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 211, with a reward 1\n",
            "Training at epoch = 211, with a reward -1\n",
            "Training at epoch = 211, with a reward -1\n",
            "Total training rewards: 9 after n steps = 211 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 212, with a reward 1\n",
            "Training at epoch = 212, with a reward -1\n",
            "Training at epoch = 212, with a reward -1\n",
            "Total training rewards: 9 after n steps = 212 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward 1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Training at epoch = 213, with a reward -1\n",
            "Total training rewards: 11 after n steps = 213 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 214, with a reward 1\n",
            "Training at epoch = 214, with a reward 1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward 1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward 1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Training at epoch = 214, with a reward -1\n",
            "Total training rewards: -13 after n steps = 214 with final reward = -10 with a winner :Human\n",
            "Taking a random walk\n",
            "Training at epoch = 215, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 215, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 215, with a reward -1\n",
            "Training at epoch = 215, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 215, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 215, with a reward 1\n",
            "Training at epoch = 215, with a reward -1\n",
            "Training at epoch = 215, with a reward -1\n",
            "Training at epoch = 215, with a reward 1\n",
            "Training at epoch = 215, with a reward -1\n",
            "Training at epoch = 215, with a reward -1\n",
            "Total training rewards: 7 after n steps = 215 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 216, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward 1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Training at epoch = 216, with a reward -1\n",
            "Total training rewards: 13 after n steps = 216 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 217, with a reward 1\n",
            "Training at epoch = 217, with a reward 1\n",
            "Training at epoch = 217, with a reward -1\n",
            "Training at epoch = 217, with a reward -1\n",
            "Training at epoch = 217, with a reward 1\n",
            "Training at epoch = 217, with a reward -1\n",
            "Training at epoch = 217, with a reward -1\n",
            "Total training rewards: 9 after n steps = 217 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 218, with a reward 1\n",
            "Training at epoch = 218, with a reward -1\n",
            "Training at epoch = 218, with a reward -1\n",
            "Training at epoch = 218, with a reward -1\n",
            "Training at epoch = 218, with a reward 1\n",
            "Training at epoch = 218, with a reward -1\n",
            "Training at epoch = 218, with a reward -1\n",
            "Total training rewards: 7 after n steps = 218 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 219, with a reward 1\n",
            "Training at epoch = 219, with a reward -1\n",
            "Training at epoch = 219, with a reward -1\n",
            "Training at epoch = 219, with a reward -1\n",
            "Training at epoch = 219, with a reward 1\n",
            "Training at epoch = 219, with a reward -1\n",
            "Training at epoch = 219, with a reward -1\n",
            "Total training rewards: 7 after n steps = 219 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 220, with a reward 1\n",
            "Training at epoch = 220, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 220, with a reward -1\n",
            "Training at epoch = 220, with a reward -1\n",
            "Training at epoch = 220, with a reward 1\n",
            "Training at epoch = 220, with a reward -1\n",
            "Training at epoch = 220, with a reward -1\n",
            "Total training rewards: 9 after n steps = 220 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward 1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Training at epoch = 221, with a reward -1\n",
            "Total training rewards: 11 after n steps = 221 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward -1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward -1\n",
            "Training at epoch = 222, with a reward -1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward 1\n",
            "Training at epoch = 222, with a reward -1\n",
            "Total training rewards: 13 after n steps = 222 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 223, with a reward 1\n",
            "Training at epoch = 223, with a reward -1\n",
            "Training at epoch = 223, with a reward -1\n",
            "Training at epoch = 223, with a reward -1\n",
            "Training at epoch = 223, with a reward 1\n",
            "Training at epoch = 223, with a reward -1\n",
            "Training at epoch = 223, with a reward -1\n",
            "Total training rewards: 7 after n steps = 223 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 224, with a reward 1\n",
            "Training at epoch = 224, with a reward -1\n",
            "Training at epoch = 224, with a reward -1\n",
            "Total training rewards: 9 after n steps = 224 with final reward = 10 with a winner :Agent\n",
            "Taking a random walk\n",
            "Training at epoch = 225, with a reward 1\n",
            "Training at epoch = 225, with a reward -1\n",
            "Training at epoch = 225, with a reward 1\n",
            "Training at epoch = 225, with a reward 1\n",
            "Training at epoch = 225, with a reward 1\n",
            "Training at epoch = 225, with a reward -1\n",
            "Training at epoch = 225, with a reward -1\n",
            "Total training rewards: 11 after n steps = 225 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 226, with a reward 1\n",
            "Training at epoch = 226, with a reward -1\n",
            "Training at epoch = 226, with a reward -1\n",
            "Total training rewards: 9 after n steps = 226 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 227, with a reward 1\n",
            "Training at epoch = 227, with a reward 1\n",
            "Training at epoch = 227, with a reward 1\n",
            "Training at epoch = 227, with a reward -1\n",
            "Training at epoch = 227, with a reward 1\n",
            "Training at epoch = 227, with a reward -1\n",
            "Training at epoch = 227, with a reward -1\n",
            "Total training rewards: 11 after n steps = 227 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 228, with a reward 1\n",
            "Training at epoch = 228, with a reward 1\n",
            "Training at epoch = 228, with a reward -1\n",
            "Taking a random walk\n",
            "Total training rewards: -9 after n steps = 228 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 229, with a reward 1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Training at epoch = 229, with a reward 1\n",
            "Training at epoch = 229, with a reward 1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Training at epoch = 229, with a reward 1\n",
            "Training at epoch = 229, with a reward 1\n",
            "Training at epoch = 229, with a reward -1\n",
            "Total training rewards: 9 after n steps = 229 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 230, with a reward 1\n",
            "Training at epoch = 230, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 230, with a reward 1\n",
            "Training at epoch = 230, with a reward -1\n",
            "Training at epoch = 230, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 230, with a reward 1\n",
            "Training at epoch = 230, with a reward 1\n",
            "Total training rewards: -7 after n steps = 230 with final reward = -10 with a winner :Human\n",
            "Copying main network weights to the target network weights\n",
            "Taking a random walk\n",
            "Training at epoch = 231, with a reward 1\n",
            "Training at epoch = 231, with a reward 1\n",
            "Training at epoch = 231, with a reward 1\n",
            "Training at epoch = 231, with a reward -1\n",
            "Training at epoch = 231, with a reward 1\n",
            "Training at epoch = 231, with a reward -1\n",
            "Training at epoch = 231, with a reward -1\n",
            "Total training rewards: 11 after n steps = 231 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 232, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 232, with a reward -1\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward 1\n",
            "Training at epoch = 232, with a reward -1\n",
            "Total training rewards: 5 after n steps = 232 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 233, with a reward 1\n",
            "Training at epoch = 233, with a reward -1\n",
            "Training at epoch = 233, with a reward -1\n",
            "Training at epoch = 233, with a reward -1\n",
            "Training at epoch = 233, with a reward 1\n",
            "Training at epoch = 233, with a reward 1\n",
            "Training at epoch = 233, with a reward -1\n",
            "Total training rewards: 9 after n steps = 233 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 234, with a reward 1\n",
            "Training at epoch = 234, with a reward 1\n",
            "Training at epoch = 234, with a reward 1\n",
            "Total training rewards: 13 after n steps = 234 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 235, with a reward 1\n",
            "Training at epoch = 235, with a reward -1\n",
            "Training at epoch = 235, with a reward -1\n",
            "Total training rewards: 9 after n steps = 235 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 236, with a reward 1\n",
            "Training at epoch = 236, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 236, with a reward -1\n",
            "Training at epoch = 236, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 236, with a reward 1\n",
            "Training at epoch = 236, with a reward -1\n",
            "Training at epoch = 236, with a reward 1\n",
            "Total training rewards: -9 after n steps = 236 with final reward = -10 with a winner :Human\n",
            "Training at epoch = 237, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 237, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 237, with a reward 1\n",
            "Training at epoch = 237, with a reward 1\n",
            "Training at epoch = 237, with a reward 1\n",
            "Training at epoch = 237, with a reward -1\n",
            "Training at epoch = 237, with a reward -1\n",
            "Total training rewards: 13 after n steps = 237 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 238, with a reward 1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 238, with a reward 1\n",
            "Training at epoch = 238, with a reward 1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Training at epoch = 238, with a reward 1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Training at epoch = 238, with a reward -1\n",
            "Total training rewards: 7 after n steps = 238 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 239, with a reward 1\n",
            "Training at epoch = 239, with a reward -1\n",
            "Training at epoch = 239, with a reward -1\n",
            "Total training rewards: 9 after n steps = 239 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 240, with a reward 1\n",
            "Training at epoch = 240, with a reward -1\n",
            "Training at epoch = 240, with a reward -1\n",
            "Total training rewards: 9 after n steps = 240 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward 1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Training at epoch = 241, with a reward -1\n",
            "Total training rewards: 11 after n steps = 241 with final reward = 10 with a winner :Agent\n",
            "Copying main network weights to the target network weights\n",
            "Training at epoch = 242, with a reward 1\n",
            "Training at epoch = 242, with a reward -1\n",
            "Training at epoch = 242, with a reward -1\n",
            "Total training rewards: 9 after n steps = 242 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 243, with a reward 1\n",
            "Training at epoch = 243, with a reward -1\n",
            "Training at epoch = 243, with a reward -1\n",
            "Total training rewards: 9 after n steps = 243 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward 1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Training at epoch = 244, with a reward -1\n",
            "Total training rewards: 3 after n steps = 244 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Taking a random walk\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward 1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Training at epoch = 245, with a reward -1\n",
            "Total training rewards: 9 after n steps = 245 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 246, with a reward 1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward 1\n",
            "Training at epoch = 246, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward 1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Training at epoch = 246, with a reward -1\n",
            "Total training rewards: 7 after n steps = 246 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 247, with a reward 1\n",
            "Training at epoch = 247, with a reward 1\n",
            "Training at epoch = 247, with a reward -1\n",
            "Total training rewards: 11 after n steps = 247 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 248, with a reward 1\n",
            "Training at epoch = 248, with a reward -1\n",
            "Training at epoch = 248, with a reward -1\n",
            "Total training rewards: 9 after n steps = 248 with final reward = 10 with a winner :Agent\n",
            "Training at epoch = 249, with a reward 1\n",
            "Taking a random walk\n",
            "Training at epoch = 249, with a reward -1\n",
            "Training at epoch = 249, with a reward -1\n",
            "Training at epoch = 249, with a reward -1\n",
            "Training at epoch = 249, with a reward 1\n",
            "Training at epoch = 249, with a reward 1\n",
            "Training at epoch = 249, with a reward -1\n",
            "Total training rewards: 9 after n steps = 249 with final reward = 10 with a winner :Agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(13,7))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Winning Number\")\n",
        "plt.plot(range(0,len(train_list_performace)),train_list_performace)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "lp_YyPnX0HBv",
        "outputId": "fabbd603-0f5a-42d5-d4ac-94e7a08b091f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd1663566d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 20\n",
        "n_wins=0\n",
        "for episode in range(1, episodes+1):\n",
        "    current_state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    human_play=True\n",
        "    while not done:\n",
        "        if human_play:\n",
        "          env.step(np.random.choice(np.arange(0,7)),1)\n",
        "          #print(\"Random is playing: \")\n",
        "          human_play=False\n",
        "          #print(\"Current State:\")\n",
        "          #print(current_state) \n",
        "          continue\n",
        "        else: \n",
        "          #print(\"Agent is playing: \")\n",
        "          action = model.predict(current_state)\n",
        "          action = predicted.argmax(axis=1)[1]\n",
        "          current_state, reward, done, info = env.step(action,-1)\n",
        "          #print(\"Current action is: \",action)\n",
        "          #print(\"Collected reward is: \",reward)\n",
        "          score+=reward\n",
        "          #print(\"Current State:\")\n",
        "          #print(current_state)  \n",
        "          human_play=True\n",
        "    if done:\n",
        "      print(\"Game was done at episode {} with a score of {}\".format(episode,score))   \n",
        "      if info[\"winner\"]==\"Agent\":\n",
        "        n_wins+=1   \n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "\n",
        "print(\"Total iterations won by agent is: {}\".format(n_wins))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMlaiEGzzJya",
        "outputId": "c034594b-83ff-47a0-826a-2ce6418cf553"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game was done at episode 1 with a score of -10000\n",
            "Episode:1 Score:-10000\n",
            "Game was done at episode 2 with a score of 9\n",
            "Episode:2 Score:9\n",
            "Game was done at episode 3 with a score of 9\n",
            "Episode:3 Score:9\n",
            "Game was done at episode 4 with a score of -9998\n",
            "Episode:4 Score:-9998\n",
            "Game was done at episode 5 with a score of -10002\n",
            "Episode:5 Score:-10002\n",
            "Game was done at episode 6 with a score of 9\n",
            "Episode:6 Score:9\n",
            "Game was done at episode 7 with a score of -10003\n",
            "Episode:7 Score:-10003\n",
            "Game was done at episode 8 with a score of 10\n",
            "Episode:8 Score:10\n",
            "Game was done at episode 9 with a score of 9\n",
            "Episode:9 Score:9\n",
            "Game was done at episode 10 with a score of -11\n",
            "Episode:10 Score:-11\n",
            "Game was done at episode 11 with a score of 9\n",
            "Episode:11 Score:9\n",
            "Game was done at episode 12 with a score of 9\n",
            "Episode:12 Score:9\n",
            "Game was done at episode 13 with a score of 9\n",
            "Episode:13 Score:9\n",
            "Game was done at episode 14 with a score of 11\n",
            "Episode:14 Score:11\n",
            "Game was done at episode 15 with a score of 9\n",
            "Episode:15 Score:9\n",
            "Game was done at episode 16 with a score of 11\n",
            "Episode:16 Score:11\n",
            "Game was done at episode 17 with a score of 10\n",
            "Episode:17 Score:10\n",
            "Game was done at episode 18 with a score of 11\n",
            "Episode:18 Score:11\n",
            "Game was done at episode 19 with a score of 10\n",
            "Episode:19 Score:10\n",
            "Game was done at episode 20 with a score of 9\n",
            "Episode:20 Score:9\n",
            "Total iterations won by agent is: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"DQN_C4.h5\")"
      ],
      "metadata": {
        "id": "gOKcITNC0eun"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mTOeapl20yO",
        "outputId": "d12afedb-b7fc-401f-aee2-d98352ed5d16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "MqfME2Wl25J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235c4486-7088-425f-d4f9-882bb179951a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 6, 48)             384       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 6, 48)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6, 16)             784       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6, 7)              119       \n",
            "=================================================================\n",
            "Total params: 1,287\n",
            "Trainable params: 1,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}